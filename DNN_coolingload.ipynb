{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN_coolingload.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNL5Wx8GeFqa8bppS6IDw0v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingchiehchan/Bayesian-Analysis-with-Python/blob/master/DNN_coolingload.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cADmt-OJ8h25"
      },
      "source": [
        "import sys\r\n",
        "sys.path.append('/content/submodel_class')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFUg0pJO9mur",
        "outputId": "60d545e3-2cc4-4ae1-c77a-9a693b0149ca"
      },
      "source": [
        "pip install silence_tensorflow"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting silence_tensorflow\n",
            "  Downloading https://files.pythonhosted.org/packages/96/d7/076b21d0e79cfc8a085f623e6577b754c50a42cfbcce51d77d0d2206988c/silence_tensorflow-1.1.1.tar.gz\n",
            "Building wheels for collected packages: silence-tensorflow\n",
            "  Building wheel for silence-tensorflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for silence-tensorflow: filename=silence_tensorflow-1.1.1-cp36-none-any.whl size=3743 sha256=29124fc55c5cceb4cf385c324aff3875013f540a264fba635b81bdfad2166730\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/0b/35/cf3020764bee61daa81fa249df3a448e3806344a087fc12292\n",
            "Successfully built silence-tensorflow\n",
            "Installing collected packages: silence-tensorflow\n",
            "Successfully installed silence-tensorflow-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "XC9FpGwX8lNL",
        "outputId": "98ed8eb9-781f-4b56-dc26-301ff8d051c8"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn import metrics\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from silence_tensorflow import silence_tensorflow\r\n",
        "silence_tensorflow()\r\n",
        "from top_factory import factory_loading"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-65896313c6e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msilence_tensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msilence_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msilence_tensorflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtop_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfactory_loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/submodel_class/top_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEpistemic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maleatory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSourceDataCls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mfactory_loading\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     self.model_task={'epistemic':epistemic,\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Epistemic'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdiWxSdM8gBY"
      },
      "source": [
        "def get_loss(predy,truey):#參數不能有特殊值成員(na inf) R2會error\r\n",
        "  dict_los={'MAE':np.nan,'RMSE':np.nan,'MAPE':np.nan,'R2':np.nan}\r\n",
        "  dict_los['R2']=metrics.r2_score(truey,predy)\r\n",
        "  dict_los['MAE']=metrics.mean_absolute_error(truey,predy)\r\n",
        "  dict_los['RMSE']=metrics.mean_squared_error(truey,predy,squared=False)\r\n",
        "  mask=truey!=0#實際為0的值我預設要剔除(會得出無限)\r\n",
        "  dict_los['MAPE']=np.sum(np.abs((truey[mask]-predy[mask])/truey[mask]))/len(truey[mask])#MAPE sklearn只有未穩定版本\r\n",
        "  return dict_los\r\n",
        "\r\n",
        "def set_traintest(df,day,count,rang):\r\n",
        "  X_trainN=df.loc[(day >= count) & (day < count+rang),:df.columns[-2]].values\r\n",
        "  Y_trainN=df.loc[(day >= count) & (day < count+rang),df.columns[-1]].values\r\n",
        "  X_testN=df.loc[(day == count+rang),:df.columns[-2]].values\r\n",
        "  Y_testN=df.loc[(day == count+rang),df.columns[-1]].values\r\n",
        "  idx=df.loc[(day == count+rang)].index\r\n",
        "  return X_trainN,Y_trainN,X_testN,Y_testN,idx\r\n",
        "\r\n",
        "factory=factory_loading()\r\n",
        "load_unit=factory.get_loadObj()\r\n",
        "load_unit.file_dict['outList']=['Secondary side kW']\r\n",
        "load_unit.file_dict['featureList']=['estimated_Irr', 'temperature', '12_Tavg', 'humidity', 'hour', 'holiday']\r\n",
        "#載入程序 需使用者自訂 強轉時序標籤與選擇所要Columns->trans_TimeSerDataset(path,df.index equal function,need columns)\r\n",
        "#load_unit.trans_TimeSerDataset('/content/new_forcast_set.csv',lambda df:pd.to_datetime(df.iloc[:,1]),\r\n",
        "#                ['estimated_Irr', 'temperature', '12_Tavg', 'humidity', 'hour','isHoliday'])\r\n",
        "feadf=pd.read_csv('/content/2020new_forcast_setDay.csv',index_col=0)\r\n",
        "feadf['time']=pd.to_datetime(feadf['time'])\r\n",
        "feadf.set_index('time',inplace=True)\r\n",
        "feadf=feadf.loc[:,['estimated_Irr', 'temperature', 'humidity','holiday']]\r\n",
        "feadf['hour']=feadf.index.hour\r\n",
        "feadf=feadf[['estimated_Irr', 'temperature', 'humidity', 'hour', 'holiday']]\r\n",
        "for i in range(1,13):\r\n",
        "  feadf[f'{i}_hour_T']=feadf['temperature'].shift(i)\r\n",
        "load_unit.push_TimeSerData(feadf,lambda x:x.loc['2020-01-01 00:00:00':'2020-12-31 23:00:00',:])\r\n",
        "\r\n",
        "load_unit.trans_TimeSerDataset('/content/input2020.csv', lambda df:pd.to_datetime(df.iloc[:,0]),['Secondary side kW'])\r\n",
        "#建置dataset\r\n",
        "load_unit.get_dataset('2019-01-01 00:00:00','2019-12-31 23:00:00','1H')\r\n",
        "#dataset插入行 所依照的是由載入程序留下的columns決定 而不是建好的dataset\r\n",
        "load_unit.insert_col(2,'12_Tavg',lambda x:x.loc[:,'1_hour_T':'12_hour_T'].mean(axis=1))\r\n",
        "#縮放 並將hourmode設置\r\n",
        "#normdf=load_unit.scaler()\r\n",
        "\r\n",
        "modeltype='aleatory'\r\n",
        "#modeltype='epistemic'\r\n",
        "DNN_MODEL=factory.get_modelObj(normdf.shape[1]-1,modeltype)#選擇MODEL種類\r\n",
        "\r\n",
        "weeknum=2\r\n",
        "traindays=7*weeknum #周數\r\n",
        "totaldays=367#終止天數\r\n",
        "startingday=1#起始天數\r\n",
        "dict_df={'idx':[],'act':[],'mean':[],'std':[],'upper':[],'lower':[]}\r\n",
        "for i in range(startingday,totaldays-traindays):#每次滑動一天 重新complie model\r\n",
        "  X_trainN,Y_trainN,X_testN,Y_testN,idx=set_traintest(normdf,normdf.index.dayofyear,i,traindays)\r\n",
        "  DNN_MODEL.build_model()#重新complie model building\r\n",
        "  if X_trainN.shape[0]>0 and X_testN.shape[0]>0:\r\n",
        "    history =DNN_MODEL.fit(X_trainN, Y_trainN)\r\n",
        "    print(f\"{idx[-1].date()}:{history}\")\r\n",
        "    if not np.isnan(history):#模組未發散再記\r\n",
        "        pred=DNN_MODEL.pred(X_testN)\r\n",
        "        dict_df['act'].extend(load_unit.sclY.inverse_transform(Y_testN).ravel())\r\n",
        "        DNN_MODEL.get_val_inverse_summary(dict_df,load_unit.sclY,pred)\r\n",
        "        dict_df['idx'].extend(idx)\r\n",
        "\r\n",
        "ans=pd.DataFrame(dict_df)\r\n",
        "ans.set_index('idx',inplace=True)\r\n",
        "ans.to_csv(f\"{load_unit.file_dict['hourmode']}_{DNN_MODEL.model_dict['layer_num']}node_24HR_{DNN_MODEL.model_dict['modelType']}.csv\")\r\n",
        "pd.DataFrame(get_loss(ans['mean'],ans['act']),index=[0]).to_csv(f'loss{weeknum}w.csv')\r\n",
        "plt.figure(figsize=(30,15))\r\n",
        "plt.xticks(rotation=90,fontsize=25)\r\n",
        "plt.yticks(fontsize=25)\r\n",
        "plt.plot(ans.index,ans['act'],'r',label='act')\r\n",
        "plt.plot(ans.index,ans['mean'],'b',label='prediction')\r\n",
        "plt.fill_between(ans.index,ans['upper'],ans['lower'],alpha=0.3,color='g')\r\n",
        "plt.legend(fontsize=25)\r\n",
        "plt.savefig(f'{weeknum}w.png')\r\n",
        "\r\n",
        "import plotly.graph_objects as go\r\n",
        "fig = go.Figure()\r\n",
        "fig.add_trace(go.Scatter(x=ans.index, y=ans['upper'],\r\n",
        "                         mode = 'lines',\r\n",
        "                         fillcolor='rgba(255,255,255,0)',\r\n",
        "                         line_color='rgba(0,255,0,0.3)',\r\n",
        "                         name=\"\",\r\n",
        "                         fill='tozeroy'))\r\n",
        "\r\n",
        "fig.add_trace(go.Scatter(x=ans.index, y=ans['lower'],\r\n",
        "                         mode = 'lines',\r\n",
        "                         fillcolor='rgba(0,255,0,0.3)',\r\n",
        "                         line_color='rgba(0,255,0,0.3)',\r\n",
        "                         name=\"fillrange\",\r\n",
        "                         fill='tonexty'))\r\n",
        "fig.add_trace(go.Scatter(x=ans.index, y=ans['act'],\r\n",
        "                         mode ='lines',\r\n",
        "                         line_color='rgba(255,0,0,1)',\r\n",
        "                         name=\"act\"\r\n",
        "                         ))\r\n",
        "fig.add_trace(go.Scatter(x=ans.index, y=ans['mean'],\r\n",
        "                         mode ='lines',\r\n",
        "                         line_color='rgba(0,0,255,1)',\r\n",
        "                         name=\"prediction\"\r\n",
        "                         ))\r\n",
        "\r\n",
        "fig.update_xaxes(\r\n",
        "        tickangle = 90,\r\n",
        "        title_font = {\"size\": 20},\r\n",
        "        title_standoff = 25)\r\n",
        "\r\n",
        "fig.update_yaxes(\r\n",
        "        title_font = {\"size\": 20},\r\n",
        "        title_standoff = 25)\r\n",
        "\r\n",
        "fig.show()\r\n",
        "\r\n",
        "#from google.colab import files\r\n",
        "#files.download(f'loss{weeknum}w.csv')\r\n",
        "#files.download(f\"{load_unit.file_dict['hourmode']}_{DNN_MODEL.model_dict['layer_num']}node_24HR_{DNN_MODEL.model_dict['modelType']}.csv\")\r\n",
        "#files.download(f\"{weeknum}w.png\")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}